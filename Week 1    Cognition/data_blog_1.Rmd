---
title: 'Data Exploration: Making Decisions'
author: "Adams"
date: "September 14, 2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
urlcolor: blue
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(estimatr) # difference_in_means()
library(broom)
library(gt)

```


Cognitive biases effect decisions that we all make every day. There are many examples of different biases, but two common ones that we have 
explored are 'heuristics', or mental shortcuts that the brain takes when it is being lazy, and the cognitive bias that can be generated by social pressure. These biases play an important role in our decision making and can be manipulated for the benefit of others, such as by politicians to secure votes and further their campaign. 

Before we started exploring this idea our class took a survey in which they were asked a number of questions which we were then able to use to expose our biases. The questions included some background data such as our gender, class and whether we had studied statistics before and then three problems: the disease policy problem, the cab colour problem and the Linda problem. 

```{r biases, message = FALSE, include=F}

bias_data <- read_csv("bias_data.csv")


prop <- bias_data %>%
summarize(prop = mean(linda == "teller"))

bias_data %>% filter(year == "Man") %>% summarize(x = mean(linda == "teller"))
bias_data %>% filter(gender == "Woman") %>% summarize(x = mean(linda == "teller"))

```

The Linda problem presents a scenario where we are given some information and then asked a question relating to the background information. The bias that some respondents fall foul of is assuming that two or more specific conditions are more probable than just one condition alone - known as conjunction fallacy. The problem and explanation were set out by Kahneman (2003). 

With 85 respondents in our class, the proportion which answered correctly that Linda was just a teller was `prop`. This is in line with the findings of Kahneman and shows how we overlook the data we are given and get the wrong answer via heuristics. 

As the subject of this question had a reasonably relatable university experience at to university to many woman in the class I thought it'd be interesting to see how the different genders answered the question, as I thought maybe the assumption that Linda would also be a feminist would be easier to make for woman. I found that the proportion of woman that answered correctly was 0.65 compared to 0.75 in men, suggesting that this could be the case.

```{r, echo=F, warning=F}

bias_data$year[bias_data$year=="4+"]<-"4"
bias_data$year <- as.numeric(bias_data$year)

model <- bias_data %>% 
  filter(gender != "Non-binary") %>% 
  mutate(linda_stat = ifelse(grepl("fem", linda), 1, 0)) %>% 
  lm(linda_stat ~ year, .) %>% 
  tidy(conf.int = T) %>% 
  select(-c(std.error, p.value, statistic)) %>% 
  mutate(term = c("Intercept", "Year")) %>% 
  gt() %>% 
  tab_header(title = "Regression Model") %>% 
  cols_label(term = "",
             estimate = "Coefficient",
             conf.low = "5th percentile",
             conf.high = "95th percentile") %>%
  tab_spanner(label = "Confidence Interval",
              columns = 3:4) %>% 
  fmt_number(., columns = vars("estimate", "conf.low", "conf.high"), decimals = 2)
  
model

```


I thought it would also be interesting to see if the year the respondent was in would change the likelihood of falling foul of the conjuntion fallacy. The results are in the table above and can be interpreted as an associated increase of, on average, -0.06 units of score for each year we increase. this means that as the year group increases we were slightly more likely to get the answer correct (for simplicity I made the correct answer 0 and the wrong answer 1 - thus the negative slope of the regression line). The reason for this may be that older students have studied this in a stat class or a psychology class, or it may just be that they were less distracted by the fallacy.   




