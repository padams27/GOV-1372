---
title: "Personality and Worldview"
author: "Paddy Adams"
date: "October 7, 2021"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(readr) # read_csv
library(ggplot2) # ggplot
library(tidyr)
library(gridExtra) # grid.arrange
library(psych) #fa.parallel
library(gt)
library(ggcorrplot)
library(broom)

```

# Measuring Personality


```{r, message=FALSE}

personality_data <- read_csv('Oct7ClassData.csv')

```


The idea behind this weeks work was to analyze each others personal living space to establish a personality profile following the Personal Living Space Cue Inventory (PLSCI) (Gosling et al. 2005). From this causal inference we can then theoretically lean on other research that goes further and looks at how personality relates to political ideology, such as Carney et al. (2009). The end result we are looking for is that by analyzing images of our college rooms we can infer the owner's political ideology. 

We were able to analyze these correlations/causalities with the help of another class wide survey (which included IDs so we could match room photos to survey results) that included a self reported ideology, social and economic scale in the same way Carney did as well as two personality inventories: a short version of the Big Five Inventory (Rammstedt and John 2007), and the Ten Item Personality Test (TIPI) which is designed to quickly measure the big five. 

To begin with the PLSCI proved to be not a bad representative of the respondents personalities, even though it doesn't take into account SES and that we only had pictures to look at instead of visiting the rooms as it should be done (missing the last few data points). The inter-coder reliability of our group was very high and our results in turn matched up well with the original self-reported data, demonstrating that the test was reliable (at least in this instance). Another obvious issue with the test is that it is outdated when applied to modern college rooms, as students no longer posses CD's nor magazines and as such asking if 'the CD's were neatly stored' is a redundant question. 

When comparing the class TIPI results to the larger dataset produced by Gosling et al. I got these results:

```{r, include=TRUE}

norms <- data.frame(All = c("Mean", "SD"),
                    E = c(4.44, 1.45),
                    A = c(5.23, 1.11),
                    C = c(5.40, 1.32),
                    ES = c(4.83, 1.42),
                    O = c(5.38, 1.07)) %>% 
  gt() %>% 
  tab_header(title = "Normative data for the TIPI: Self-reported data")


class_norms <- personality_data %>% 
  select(10:14) %>% 
  summarise_all(~ c(mean(.), sd(.))) %>% 
  round(., 2) %>% 
  rename(E = TIPI_extraversion,
         A = TIPI_agreeableness,
         C = TIPI_conscientiousness,
         ES = TIPI_emot_stability,
         O = TIPI_openness) %>% 
  mutate(All = c("Mean", "SD"), .before = "E") %>% 
  gt() %>% 
  tab_header(title = "Class Data for the TIPI") %>% 
  tab_options(table.width = pct(50))
  

norms


class_norms

```


These tables show that our class averages for the TIBI were very close to the averages of the Gosling et al. (2003) report that involved 1800 participants. The significant differences were a 0.29 increase in the mean of 'Extraversion', a 0.35 reduction in 'Agreeableness' and a 0.29 decrease in 'Emotional Stability'. I would suggest that this is due to the higher number of 'liberal' respondents that exist in a Harvard Gov class, as higher emotional stability, lower extraversion and lower agreeableness are all linked to the respondents being more conservative. This makes sense when we consider how the demographic of our class differs from even other college cohorts let alone the general population. 


Given the causal inference we are assuming in order to get from analyzing someones room to identifying their political ideology there is more chance we may compound errors. Therefore it is only normal to test just how reliable the data is in the intermediary steps, and the two personality tests provide a good example of this. If the theory behind the path of causation that we are following is correct then both tests should be giving very similar results and as such the measures of the five personality points should show a strong positive correlation:


```{r, include=TRUE}

# five point scale 

cor_5 <- personality_data %>% 
  select(5:14) %>% 
  drop_na() %>% 
  cor() %>% 
  as.data.frame()

table <- cor_5 %>% 
  select(1:5) %>% 
  tail(5)

ggcorrplot(table, hc.order = TRUE, lab = TRUE, show.legend = FALSE)

```


It's pretty clear that there is a decent correlation amongst most of the points, however I would have expected to see them being stronger and up above the 0.8 mark as 'Extraversion' is. Of course, the result for 'Openness' is very low and raises some questions: this may be due to unreliable responses, for example misreading the prompt, or that the two scales produced very different results. The other three results show a strong similarity at 0.6, even if this isn't as strong as I would have expected. I think one of the most important reasons behind this that TIPI uses a seven point scale compared to BFI's five. This gives the BFI more consistent results, but also less accurate results.

By using a larger scale (strongly unfavourable, somewhat..., slightly..., neutral, etc) the self-reported results are more accurate but the results of the BFI are more similar. This means that when comparing the self-reported test to the room-based evaluation (PLSCI) done by peers we were able to achieve more similar results due to a smaller variation, and so in turn one could argue at this stage of the process the data is more accurate when inferring causality from PLSCI to personality. However this then flips when we look at how we deduce ideology from personality. To explore this I ran a regression on both the TIPI and BFI results to see how each point relate to overall self-reported ideology:


```{r, include = TRUE}


personality_data %>% 
  lm(Overall ~ TIPI_extraversion + TIPI_agreeableness + TIPI_conscientiousness + TIPI_emot_stability + TIPI_openness, .) %>% 
  tidy() %>% 
  gt() %>% 
  fmt_number(columns = 2:5, decimals = 3)


personality_data %>% 
  lm(Overall ~ BFI_extraversion + BFI_agreeableness + BFI_conscientiousness + BFI_emot_stability + BFI_openness, .) %>% 
  tidy() %>% 
  gt() %>% 
  fmt_number(columns = 2:5, decimals = 3)


```


The TIPI test proved to be a far better test in this circumstance, with the only two statistically significant results from either. The two results from the TIPI test with a p-value below 0.05, 'Agreeableness' and 'Conscientiousness', show that they are the strongest indicators of political ideology, and support the differences we saw earlier in the skewed representation of ideology of a Harvard class when compared to the respondents of the Gosling et al. study. These two indicators were the best for predicting ideology, with higher conscientiousness causing greater chance of being more conservaitve and visa versa for agreeableness. 















